# NNUE Training System for Chess Evaluation

This system trains NNUE (Efficiently Updatable Neural Networks) models using chess positions generated by your Database application. The trained models can be used in chess engines for position evaluation.

## Features

- **GPU-Accelerated Training**: Uses PyTorch with CUDA support for fast training
- **HalfKP Feature Encoding**: Standard NNUE feature representation
- **Database Integration**: Loads training data directly from your chess database
- **Model Export**: Exports to multiple formats (.nnue, ONNX, PyTorch Mobile)
- **Evaluation Tools**: Comprehensive model analysis and comparison tools
- **Deduplication**: Uses Zobrist-like hashing to filter unique positions

## Requirements

### System Requirements
- Python 3.8 or higher
- NVIDIA GPU with CUDA support (recommended for training)
- SQL Server with ODBC Driver 17
- At least 8GB RAM (16GB+ recommended)
- 50GB+ free disk space for models and data

### Python Dependencies
See `requirements.txt` for complete list. Key dependencies:
- PyTorch 2.0+
- python-chess
- pyodbc
- numpy
- tqdm

## Installation

1. **Clone or download the NNUE training files**
2. **Install Python dependencies:**
   ```bash
   pip install -r requirements.txt
   ```
3. **Install CUDA PyTorch (for GPU training):**
   ```bash
   # For CUDA 11.8 (adjust version as needed)
   pip install torch torchvision --index-url https://download.pytorch.org/whl/cu118
   ```
4. **Run setup script:**
   ```bash
   python setup.py
   ```

## Quick Start

1. **Test database connection:**
   ```bash
   python NNUE.py --test-connection
   ```

2. **Quick training test:**
   ```bash
   python quick_start.py
   ```

3. **Full training:**
   ```bash
   python NNUE.py --batch-size 8192 --epochs 100 --max-positions 1000000
   ```

## Configuration

### Database Connection
Update the connection string in your configuration:
```python
connection_string = "Server=localhost\\SQLEXPRESS;Database=ChessDatabase;Trusted_Connection=True;Driver={ODBC Driver 17 for SQL Server};"
```

### Training Parameters
Key parameters you can adjust:

| Parameter | Default | Description |
|-----------|---------|-------------|
| `batch_size` | 8192 | Training batch size (reduce if GPU memory issues) |
| `learning_rate` | 0.001 | Learning rate for optimizer |
| `epochs` | 100 | Number of training epochs |
| `max_positions` | 1000000 | Maximum positions to load from database |
| `min_ply` | 16 | Minimum game ply for training positions |
| `hidden_size` | 256 | Size of hidden layers |

### GPU Memory Optimization
If you encounter GPU memory issues:
- Reduce `batch_size` (try 4096, 2048, or 1024)
- Reduce `num_workers` for data loading
- Use gradient accumulation for effective larger batches

## Usage Examples

### Basic Training
```bash
# Start training with default parameters
python NNUE.py

# Training with custom parameters
python NNUE.py --batch-size 4096 --epochs 50 --learning-rate 0.0005
```

### Model Evaluation
```bash
# Evaluate trained model
python model_eval.py models/chess_nnue_best.pth --benchmark

# Compare with Stockfish
python model_eval.py models/chess_nnue_best.pth --compare-engine stockfish.exe

# Analyze feature importance
python model_eval.py models/chess_nnue_best.pth --analyze-features
```

### Model Export
```bash
# Export to .nnue format for engines
python model_eval.py models/chess_nnue_best.pth --export-nnue my_model.nnue

# Export to ONNX
python model_eval.py models/chess_nnue_best.pth --export-onnx my_model.onnx
```

## Training Data

The system loads data from your ChessMoves and ChessGames tables with these filters:
- Positions from games with definitive results (1-0, 0-1, 1/2-1/2)
- Minimum ply count to avoid opening book positions
- Evaluation magnitude limits to filter extreme positions
- Zobrist-like deduplication to ensure unique positions

### Data Quality Tips
- Ensure your database has sufficient move diversity
- Games from different time controls improve generalization
- Consider filtering by engine strength or game quality
- More data generally improves model performance

## Model Architecture

The NNUE model uses a standard architecture:
- **Input**: 768 HalfKP features (64 squares × 12 pieces ÷ 2)
- **Feature Transformer**: 768 → 256 → 32
- **Output Network**: 32 → 32 → 1
- **Activation**: ReLU for hidden layers, Tanh for output

## Output Files

### Training Outputs
- `models/chess_nnue_best.pth` - Best model checkpoint
- `models/chess_nnue_epoch_N.pth` - Regular epoch saves
- `nnue_training.log` - Training logs
- `logs/` - Additional logging files

### Exported Models
- `*.nnue` - Engine-compatible format
- `*.onnx` - ONNX format for cross-platform use
- `*.ptl` - PyTorch Mobile format

## Integration with Chess Engines

### Stockfish Integration
1. Export model to .nnue format:
   ```bash
   python model_eval.py models/chess_nnue_best.pth --export-nnue my_engine.nnue
   ```
2. Copy the .nnue file to your Stockfish directory
3. Use the `EvalFile` UCI option to load your model

### Custom Engine Integration
The exported .nnue files follow a standard format that can be integrated into:
- Stockfish-based engines
- Custom UCI engines
- Engine tournaments and analysis

## Monitoring Training

### Real-time Monitoring
- Watch training loss in console output
- Check GPU utilization with `nvidia-smi`
- Monitor disk space in output directories

### Training Progress
- Training loss should decrease consistently
- Validation loss should track training loss
- Large gaps indicate overfitting (reduce learning rate)

### Stopping Criteria
Training can be stopped when:
- Validation loss stops improving (early stopping)
- Desired performance is reached
- Time/resource constraints

## Troubleshooting

### Common Issues

**Database Connection Failed**
- Check SQL Server is running
- Verify connection string
- Ensure ODBC Driver 17 is installed

**CUDA Out of Memory**
- Reduce batch size
- Close other GPU applications
- Use CPU training if necessary

**Low Training Speed**
- Enable GPU training with CUDA
- Increase num_workers for data loading
- Use SSD storage for data directory

**Poor Model Performance**
- Increase training data size
- Train for more epochs
- Adjust learning rate
- Check data quality and diversity

### Performance Optimization

**GPU Training**
- Use CUDA-enabled PyTorch
- Maximize batch size within GPU memory
- Use mixed precision training (experimental)

**Data Loading**
- Increase num_workers (but not too high)
- Use fast storage (SSD) for data
- Consider data preprocessing/caching

**Model Architecture**
- Experiment with hidden layer sizes
- Try different activation functions
- Consider regularization techniques

## Advanced Usage

### Custom Feature Engineering
Modify the `HalfKPFeatures` class to experiment with:
- Different piece representations
- King safety features
- Pawn structure encoding
- Material imbalance features

### Training Strategies
- Curriculum learning (start with easier positions)
- Multi-task learning (predict game outcome + evaluation)
- Ensemble methods (combine multiple models)
- Transfer learning from existing models

### Evaluation Metrics
Monitor additional metrics:
- Correlation with engine evaluations
- Prediction accuracy on test games
- Performance on tactical positions
- Speed benchmarks

## Contributing

To contribute improvements:
1. Test changes thoroughly
2. Document new features
3. Maintain backward compatibility
4. Follow Python coding standards

## References

- [NNUE Paper](https://arxiv.org/abs/2007.02130)
- [Stockfish NNUE](https://stockfishchess.org/blog/2020/introducing-nnue-evaluation/)
- [PyTorch Documentation](https://pytorch.org/docs/)
- [Chess Programming Wiki](https://www.chessprogramming.org/NNUE)

## License

This NNUE training system is provided as-is for educational and research purposes. Please respect the licenses of the underlying dependencies (PyTorch, python-chess, etc.).
